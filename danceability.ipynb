{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports and file-reading support.\n",
    "from hdf5_getters import * \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "##JustSparkThings.\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "def dir_explorer(root): \n",
    "    file_paths = []\n",
    "    walker = os.walk(root)\n",
    "    for (path, dirnames, filenames) in walker:\n",
    "        for filename in filenames:\n",
    "            file_paths.append(os.path.join(path, filename))\n",
    "    return file_paths\n",
    "\n",
    "def get_title_year_danceability(filename):\n",
    "    f = open_h5_file_read(filename)\n",
    "    title = get_title(f)\n",
    "    danceability = get_danceability(f)\n",
    "    year = get_year(f)\n",
    "    return (title.decode('utf-8'), year, danceability)\n",
    "    \n",
    "    \n",
    "conf = SparkConf().setMaster('local').setAppName('Danceability')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"Danceability\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_directory = \"/home/falapen/Skola/LDSA/Project/Data/A\"\n",
    "file_paths = dir_explorer(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_rdd = sc.parallelize(file_paths)\n",
    "song_rdd = filepath_rdd.map(get_title_year_danceability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [StructField(\"title\", StringType(), True), StructField(\"year\", IntegerType(), True), StructField(\"danceability\", FloatType(), True)]\n",
    "schema = StructType(fields)\n",
    "songs = song_rdd.map(lambda x: Row(title=x[0], year=int(x[1]), danceability=float(x[2])))\n",
    "df = spark.createDataFrame(songs, schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
